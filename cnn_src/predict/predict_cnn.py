import numpy as np
import librosa
from tensorflow.keras.models import load_model
import subprocess
import os
import uuid
import sys

# ğŸ“Œ ì„¤ì •ê°’
sr = 22050
n_mfcc = 13
hop_length = 512
max_len = 130
model_path = "cnn_model.h5"

# âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = load_model(model_path)

def plot_results(results):
    if not results:
        print("â— ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ì–´ìš”!")
        return

def convert_to_wav(file_path):
    """mp4/m4a/mp3 â†’ wavë¡œ ë³€í™˜ (ì„ì‹œ íŒŒì¼ ìƒì„±)"""
    ext = os.path.splitext(file_path)[1].lower()
    if ext == '.wav':
        return file_path

    temp_wav = f"temp_{uuid.uuid4().hex[:8]}.wav"
    command = ['ffmpeg', '-y', '-i', file_path, '-ac', '1', '-ar', str(sr), temp_wav]

    try:
        subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return temp_wav
    except subprocess.CalledProcessError:
        print("â— ffmpeg ë³€í™˜ ì‹¤íŒ¨!")
        return None

def preprocess_audio(file_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ CNN ì…ë ¥ìš© í˜•íƒœë¡œ ì „ì²˜ë¦¬"""
    y_audio, _ = librosa.load(file_path, sr=sr, duration=5.0)

    mfcc = librosa.feature.mfcc(y=y_audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length)
    zcr = librosa.feature.zero_crossing_rate(y=y_audio, hop_length=hop_length)
    features = np.vstack([mfcc, zcr])  # (14, N)

    if features.shape[1] < max_len:
        pad_width = max_len - features.shape[1]
        features = np.pad(features, ((0, 0), (0, pad_width)), mode='constant')
    else:
        features = features[:, :max_len]

    features = features[..., np.newaxis]  # (14, 130, 1)
    return np.expand_dims(features, axis=0)  # (1, 14, 130, 1)

def predict_audio(file_path):
    ext = os.path.splitext(file_path)[1].lower()
    temp_file = None

    if ext in ['.mp4', '.m4a', '.mp3']:
        print(f"ğŸ”„ ë³€í™˜ ì¤‘: {file_path} â†’ wav")
        temp_file = convert_to_wav(file_path)
        if temp_file is None:
            return
        wav_path = temp_file
    else:
        wav_path = file_path

    X_new = preprocess_audio(wav_path)
    prediction = model.predict(X_new)[0][0]

    print(f"\nğŸ” ì˜ˆì¸¡ í™•ë¥ : {prediction:.4f}")
    print("âœ… ë¶„ë¥˜ ê²°ê³¼:", "ğŸ”ˆ ì¡°ìš©í•œ ì†Œë¦¬ (quiet)" if prediction < 0.5 else "ğŸ“¢ ì‹œë„ëŸ¬ìš´ ì†Œë¦¬ (loud)")

    if temp_file and os.path.exists(temp_file):
        os.remove(temp_file)

# âœ… ì‹¤í–‰ ì§„ì…ì 
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("â— ì‚¬ìš©ë²•: python predict_cnn.py [íŒŒì¼ëª…]")
    else:
        test_file = sys.argv[1]
        if not os.path.exists(test_file):
            print(f"â— ì˜¤ë¥˜: íŒŒì¼ '{test_file}' ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ìš”.")
        else:
            predict_audio(test_file)
